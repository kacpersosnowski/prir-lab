{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-NuICG6r4Bi"
      },
      "source": [
        "Ćwiczenie wstępne z MPI. Na podstawie:\n",
        "* http://selkie.macalester.edu/DistributedPython/index.html\n",
        "\n",
        "* https://mpi4py.readthedocs.io/en/stable/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oFDYsaxVf3h6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting mpi4py\n",
            "  Using cached mpi4py-3.1.5.tar.gz (2.5 MB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for mpi4py: filename=mpi4py-3.1.5-cp39-cp39-linux_x86_64.whl size=639492 sha256=aa1a0898214c8e10d5d866a7144177d589971b066ba7687459bf90b44695958a\n",
            "  Stored in directory: /home/stud/.cache/pip/wheels/17/26/3e/a5512b087666ce03512d7eb1b16782e8b104577c3649b68633\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install mpi4py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvAAOle4ga5C",
        "outputId": "6b657d7d-9592-4c19-8187-828def4b8ee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing example0.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile example0.py\n",
        "\n",
        "from mpi4py import MPI\n",
        "\n",
        "def main():\n",
        "  comm = MPI.COMM_WORLD # komunikator zawierający wszystkie procesy\n",
        "  id = comm.Get_rank() # id aktualnego procesu\n",
        "  numProc = comm.Get_size() # liczba procesów w komunikatorze\n",
        "  hostName = MPI.Get_processor_name() # nazwa maszyny na której uruchamiany jest program\n",
        "\n",
        "  print(f\"Jestem procesem nr {id} z {numProc} uruchamianym na maszynie {hostName}\")\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KytNw2hRijaN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jestem procesem nr 0 z 4 uruchamianym na maszynie ubuntu_1804_desktop\n",
            "Jestem procesem nr 1 z 4 uruchamianym na maszynie ubuntu_1804_desktop\n",
            "Jestem procesem nr 3 z 4 uruchamianym na maszynie ubuntu_1804_desktop\n",
            "Jestem procesem nr 2 z 4 uruchamianym na maszynie ubuntu_1804_desktop\n"
          ]
        }
      ],
      "source": [
        "#uruchomienie na komputrze lokalnym:\n",
        "# mpirun -np 4 python example0.py \n",
        "# ! oraz opcja --allow-run-as-root dodane na potrzeby notatnika\n",
        "!mpirun --allow-run-as-root -np 4 python3 example0.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SROxFakHjYvy",
        "outputId": "03dac79a-da46-4101-ea05-d836fd7bed20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing example1.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile example1.py\n",
        "\n",
        "from mpi4py import MPI\n",
        "\n",
        "def main():\n",
        "  comm = MPI.COMM_WORLD # komunikator zawierający wszystkie procesy\n",
        "  id = comm.Get_rank() # id aktualnego procesu\n",
        "  numProc = comm.Get_size() # liczba procesów w komunikatorze\n",
        "  hostName = MPI.Get_processor_name() # nazwa maszyny na której uruchamiany jest program\n",
        "\n",
        "  if id == 0:\n",
        "    print(f\"Jestem procesem ** głównym ** o id {id} uruchamianym na maszynie {hostName}\")\n",
        "  else:\n",
        "    print(f\"Jestem procesem nr {id} z {numProc} uruchamianym na maszynie {hostName}\")\n",
        "\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "c1Veg0nnppef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jestem procesem nr 2 z 4 uruchamianym na maszynie ubuntu_1804_desktop\n",
            "Jestem procesem ** głównym ** o id 0 uruchamianym na maszynie ubuntu_1804_desktop\n",
            "Jestem procesem nr 3 z 4 uruchamianym na maszynie ubuntu_1804_desktop\n",
            "Jestem procesem nr 1 z 4 uruchamianym na maszynie ubuntu_1804_desktop\n"
          ]
        }
      ],
      "source": [
        "!mpirun --allow-run-as-root -np 4 python3 example1.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9ZbA1HHbLnC",
        "outputId": "01766f53-959d-4574-e1e4-cf92493f9cb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing example2.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile example2.py\n",
        "from mpi4py import MPI\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()            #number of the process running the code\n",
        "    numProcesses = comm.Get_size()  #total number of processes running\n",
        "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
        "\n",
        "    REPS = 16\n",
        "\n",
        "    if ((REPS % numProcesses) == 0 and numProcesses <= REPS):\n",
        "        # How much of the loop should a process work on?\n",
        "        # Każdy proces otrzymuje kolejno odpowiednią ilość zadań określoną jako chunkSize. np. proces 0 otrzymuje 0, 1, 2, 3. ChunkSize to 4.\n",
        "        chunkSize = int(REPS / numProcesses)\n",
        "        start = id * chunkSize\n",
        "        stop = start + chunkSize\n",
        "\n",
        "        # do the work within the range set aside for this process\n",
        "        for i in range(start, stop):\n",
        "            print(\"On {}: Process {} is performing iteration {}\"\\\n",
        "            .format(myHostName, id, i))\n",
        "\n",
        "    else:\n",
        "        # cannot break into equal chunks; one process reports the error\n",
        "        if id == 0 :\n",
        "            print(\"Please run with number of processes divisible by \\\n",
        "and less than or equal to {}.\".format(REPS))\n",
        "\n",
        "########## Run the main function\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YDsCPW6Kbho2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On ubuntu_1804_desktop: Process 3 is performing iteration 12\n",
            "On ubuntu_1804_desktop: Process 3 is performing iteration 13\n",
            "On ubuntu_1804_desktop: Process 3 is performing iteration 14\n",
            "On ubuntu_1804_desktop: Process 3 is performing iteration 15\n",
            "On ubuntu_1804_desktop: Process 1 is performing iteration 4\n",
            "On ubuntu_1804_desktop: Process 1 is performing iteration 5\n",
            "On ubuntu_1804_desktop: Process 1 is performing iteration 6\n",
            "On ubuntu_1804_desktop: Process 1 is performing iteration 7\n",
            "On ubuntu_1804_desktop: Process 2 is performing iteration 8\n",
            "On ubuntu_1804_desktop: Process 2 is performing iteration 9\n",
            "On ubuntu_1804_desktop: Process 2 is performing iteration 10\n",
            "On ubuntu_1804_desktop: Process 2 is performing iteration 11\n",
            "On ubuntu_1804_desktop: Process 0 is performing iteration 0\n",
            "On ubuntu_1804_desktop: Process 0 is performing iteration 1\n",
            "On ubuntu_1804_desktop: Process 0 is performing iteration 2\n",
            "On ubuntu_1804_desktop: Process 0 is performing iteration 3\n"
          ]
        }
      ],
      "source": [
        "! mpirun --allow-run-as-root -np 4 python3 example2.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuetR_Lmdqy9"
      },
      "source": [
        "\n",
        "*   Proszę uruchomić powyższy program użwając różnej liczby procesów (N = 1,2,4,8);  \n",
        "\n",
        "*   zmienić wartość REPS na 16\n",
        "* wyjaśnić jak schemat dzieli iteracje pętli między procesy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoBgUYizeEk-",
        "outputId": "42481f23-f09d-4849-d0fb-13b14ba436e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing example3.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile example3.py\n",
        "from mpi4py import MPI\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()            #number of the process running the code\n",
        "    numProcesses = comm.Get_size()  #total number of processes running\n",
        "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
        "\n",
        "    REPS = 8\n",
        "    #Każdy proces bierze kolejne dostępne zadanie, przez co jeśli każdy z procesów weźmie dostępne zadanie, kolejka zaczyna się od początku.\n",
        "    #Na przykład Proces 0 -> zadanie 0, proces 1 -> zadanie 1..., proces 0 -> zadanie 4... \n",
        "    if (numProcesses <= REPS):\n",
        "\n",
        "        for i in range(id, REPS, numProcesses):\n",
        "            print(\"On {}: Process {} is performing iteration {}\"\\\n",
        "            .format(myHostName, id, i))\n",
        "\n",
        "    else:\n",
        "        # can't have more processes than work; one process reports the error\n",
        "        if id == 0 :\n",
        "            print(\"Please run with number of processes less than \\\n",
        "or equal to {}.\".format(REPS))\n",
        "\n",
        "########## Run the main function\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ERboKygpkmR_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On ubuntu_1804_desktop: Process 3 is performing iteration 3\n",
            "On ubuntu_1804_desktop: Process 3 is performing iteration 7\n",
            "On ubuntu_1804_desktop: Process 1 is performing iteration 1\n",
            "On ubuntu_1804_desktop: Process 1 is performing iteration 5\n",
            "On ubuntu_1804_desktop: Process 2 is performing iteration 2\n",
            "On ubuntu_1804_desktop: Process 2 is performing iteration 6\n",
            "On ubuntu_1804_desktop: Process 0 is performing iteration 0\n",
            "On ubuntu_1804_desktop: Process 0 is performing iteration 4\n"
          ]
        }
      ],
      "source": [
        "! mpirun --allow-run-as-root -np 4 python3 example3.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMzhBSzwkziL"
      },
      "source": [
        "* Proszę uruchomić powyższy program użwając różnej liczby procesów (N = 1,2,4,8);\n",
        "\n",
        "* zmienić wartość REPS na 16\n",
        "\n",
        "* wyjaśnić jak schemat dzieli iteracje pętli między procesy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFTzISLrk7fW"
      },
      "source": [
        "Komunikacja punkt-punkt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qcQEJTCPk7J2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing example4.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile example4.py\n",
        "from mpi4py import MPI\n",
        "\n",
        "# function to return whether a number of a process is odd or even\n",
        "def odd(number):\n",
        "    if (number % 2) == 0:\n",
        "        return False\n",
        "    else :\n",
        "        return True\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()            #number of the process running the code\n",
        "    numProcesses = comm.Get_size()  #total number of processes running\n",
        "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
        "\n",
        "    if numProcesses > 1 and not odd(numProcesses):\n",
        "        #generate a list of 8 numbers, beginning with my id\n",
        "        sendList = list(range(id, id+8))\n",
        "        if odd(id):\n",
        "            #odd processes send to their 'left neighbor', then receive from\n",
        "            comm.send(sendList, dest=id-1)\n",
        "            receivedList = comm.recv(source=id-1)\n",
        "        else :\n",
        "            #even processes receive from their 'right neighbor', then send\n",
        "            receivedList = comm.recv(source=id+1)\n",
        "            comm.send(sendList, dest=id+1)\n",
        "\n",
        "        print(\"Process {} of {} on {} computed {} and received {}\"\\\n",
        "        .format(id, numProcesses, myHostName, sendList, receivedList))\n",
        "\n",
        "    else :\n",
        "        if id == 0:\n",
        "            print(\"Please run this program with the number of processes \\\n",
        "positive and even\")\n",
        "\n",
        "########## Run the main function\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PXQjxcgJoLVh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Process 0 of 4 on ubuntu_1804_desktop computed [0, 1, 2, 3, 4, 5, 6, 7] and received [1, 2, 3, 4, 5, 6, 7, 8]\n",
            "Process 1 of 4 on ubuntu_1804_desktop computed [1, 2, 3, 4, 5, 6, 7, 8] and received [0, 1, 2, 3, 4, 5, 6, 7]\n",
            "Process 2 of 4 on ubuntu_1804_desktop computed [2, 3, 4, 5, 6, 7, 8, 9] and received [3, 4, 5, 6, 7, 8, 9, 10]\n",
            "Process 3 of 4 on ubuntu_1804_desktop computed [3, 4, 5, 6, 7, 8, 9, 10] and received [2, 3, 4, 5, 6, 7, 8, 9]\n"
          ]
        }
      ],
      "source": [
        "! mpirun --allow-run-as-root -np 4 python3 example4.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-YCBUkionZe"
      },
      "source": [
        "Proszę narysować schemat komunikacji pomiędzy poszczególnymi procesami w zadaniu numer 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL8QLk7WpLIT"
      },
      "source": [
        "##Zadanie\n",
        "**Zadanie.** Proszę napisać program który generuje tablicę tablic liczb w procesie głównym i rozsyłą je do pozostałych procesów. Procesy odbierają swoją część tablicy i wyliczają oraz wypisują jej sumę;   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting zadanie1.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile zadanie1.py\n",
        "from mpi4py import MPI\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()    \n",
        "    numSideProcesses = comm.Get_size() - 1\n",
        "    myHostName = MPI.Get_processor_name()\n",
        "\n",
        "    if numSideProcesses > 1:\n",
        "        if id == 0:\n",
        "            sendList = list(range(id, id+8))\n",
        "            for i in range(numSideProcesses):\n",
        "                start = int(i * len(sendList) / numSideProcesses)\n",
        "                end = int(start + len(sendList) / numSideProcesses)\n",
        "                comm.send(sendList[start:end], dest=i+1)\n",
        "        else:\n",
        "            receivedList = comm.recv(source=0)\n",
        "            result =0\n",
        "            for element in receivedList:\n",
        "                result+=element\n",
        "            print(\"Jestem procesem o id:\", id)\n",
        "            print(\"Obliczyłem sumę:\", result)\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jestem procesem o id: 4\n",
            "Jestem procesem o id: 3\n",
            "Jestem procesem o id: 2\n",
            "Obliczyłem sumę: 5\n",
            "Obliczyłem sumę: 9\n",
            "Obliczyłem sumę: 13\n",
            "Jestem procesem o id: 1\n",
            "Obliczyłem sumę: 1\n"
          ]
        }
      ],
      "source": [
        "!mpirun --allow-run-as-root -np 5 python3 zadanie1.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2Z18A5Kqz1P"
      },
      "source": [
        "Komunikacja kolektywna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxmmtViDqzgR",
        "outputId": "33aa332b-3de4-42ba-8ac4-9f633217962b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing broadcast_example.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile broadcast_example.py\n",
        "from mpi4py import MPI\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()            #number of the process running the code\n",
        "    numProcesses = comm.Get_size()  #total number of processes running\n",
        "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
        "\n",
        "    if numProcesses > 1 :\n",
        "\n",
        "        if id == 0:        # master\n",
        "            #master: generate a dictionary with arbitrary data in it\n",
        "            data = list(range(numProcesses))\n",
        "            print(\"Master Process {} of {} on {} broadcasts {}\"\\\n",
        "            .format(id, numProcesses, myHostName, data))\n",
        "\n",
        "        else :\n",
        "            # worker: start with empty data\n",
        "            data = []\n",
        "            print(\"Worker Process {} of {} on {} starts with {}\"\\\n",
        "            .format(id, numProcesses, myHostName, data))\n",
        "\n",
        "        #initiate and complete the broadcast\n",
        "        data = comm.bcast(data, root=0)\n",
        "\n",
        "        #check the result\n",
        "        print(\"Process {} of {} on {} has {} after the broadcast\"\\\n",
        "        .format(id, numProcesses, myHostName, data))\n",
        "\n",
        "    else :\n",
        "        print(\"Please run this program with the number of processes greater than 1\")\n",
        "\n",
        "########## Run the main function\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rRSNY-R7rZUj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Worker Process 3 of 4 on ubuntu_1804_desktop starts with []\n",
            "Master Process 0 of 4 on ubuntu_1804_desktop broadcasts [0, 1, 2, 3]\n",
            "Process 0 of 4 on ubuntu_1804_desktop has [0, 1, 2, 3] after the broadcast\n",
            "Worker Process 2 of 4 on ubuntu_1804_desktop starts with []\n",
            "Process 2 of 4 on ubuntu_1804_desktop has [0, 1, 2, 3] after the broadcast\n",
            "Worker Process 1 of 4 on ubuntu_1804_desktop starts with []\n",
            "Process 1 of 4 on ubuntu_1804_desktop has [0, 1, 2, 3] after the broadcast\n",
            "Process 3 of 4 on ubuntu_1804_desktop has [0, 1, 2, 3] after the broadcast\n"
          ]
        }
      ],
      "source": [
        "! mpirun --allow-run-as-root -np 4 python3 broadcast_example.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4iARvNErWQy"
      },
      "source": [
        "Scatter, Gather "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RTlc4w1ruZx",
        "outputId": "9f53325c-4444-465a-d5bc-fe5e461050ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting 14scatter.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile 14scatter.py\n",
        "from mpi4py import MPI\n",
        "\n",
        "# Create a list of lists to be scattered.\n",
        "def genListOfLists(numElements):\n",
        "    data = [[0]*3 for i in range(numElements)]\n",
        "    for i in range(numElements):\n",
        "        #make small lists of 3 distinct elements\n",
        "        smallerList = []\n",
        "        for j in range(1,4):\n",
        "            smallerList = smallerList + [(i+1)*j]\n",
        "        # place the small list in the larger list\n",
        "        data[i] = smallerList\n",
        "    return data\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()            #number of the process running the code\n",
        "    numProcesses = comm.Get_size()  #total number of processes running\n",
        "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
        "\n",
        "    # in mpi4py, the lowercase scatter method only works on lists whose size\n",
        "    # is the total number of processes.\n",
        "    numElements = numProcesses      #total elements in list created by master process\n",
        "\n",
        "    # however, the list can contain lists, like this list of 3-element lists,\n",
        "    # for example this list of four 3-element lists:\n",
        "    #     [[1, 2, 3], [2, 4, 6], [3, 6, 9], [4, 8, 12]]\n",
        "\n",
        "    if id == 0:\n",
        "        data = genListOfLists(numElements)\n",
        "        print(\"Master {} of {} on {} has created list: {}\"\\\n",
        "        .format(id, numProcesses, myHostName, data))\n",
        "    else:\n",
        "        data = None\n",
        "        print(\"Worker Process {} of {} on {} starts with {}\"\\\n",
        "        .format(id, numProcesses, myHostName, data))\n",
        "\n",
        "    #scatter one small list in the large list on node 0 to each of the processes\n",
        "    result = comm.scatter(data, root=0)\n",
        "\n",
        "    print(\"Process {} of {} on {} has result after scatter {}\"\\\n",
        "    .format(id, numProcesses, myHostName, result))\n",
        "\n",
        "    if id == 0:\n",
        "        print(\"Master {} of {} on {} has original list after scatter: {}\"\\\n",
        "        .format(id, numProcesses, myHostName, data))\n",
        "\n",
        "########## Run the main function\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ItDGyYrqrxBA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Worker Process 6 of 8 on ubuntu_1804_desktop starts with None\n",
            "Worker Process 3 of 8 on ubuntu_1804_desktop starts with None\n",
            "Master 0 of 8 on ubuntu_1804_desktop has created list: [[1, 2, 3], [2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15], [6, 12, 18], [7, 14, 21], [8, 16, 24]]\n",
            "Process 3 of 8 on ubuntu_1804_desktop has result after scatter [4, 8, 12]\n",
            "Process 0 of 8 on ubuntu_1804_desktop has result after scatter [1, 2, 3]\n",
            "Master 0 of 8 on ubuntu_1804_desktop has original list after scatter: [[1, 2, 3], [2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15], [6, 12, 18], [7, 14, 21], [8, 16, 24]]\n",
            "Process 6 of 8 on ubuntu_1804_desktop has result after scatter [7, 14, 21]\n",
            "Worker Process 1 of 8 on ubuntu_1804_desktop starts with None\n",
            "Process 1 of 8 on ubuntu_1804_desktop has result after scatter [2, 4, 6]\n",
            "Worker Process 2 of 8 on ubuntu_1804_desktop starts with None\n",
            "Worker Process 5 of 8 on ubuntu_1804_desktop starts with None\n",
            "Worker Process 7 of 8 on ubuntu_1804_desktop starts with None\n",
            "Worker Process 4 of 8 on ubuntu_1804_desktop starts with None\n",
            "Process 4 of 8 on ubuntu_1804_desktop has result after scatter [5, 10, 15]\n",
            "Process 2 of 8 on ubuntu_1804_desktop has result after scatter [3, 6, 9]\n",
            "Process 5 of 8 on ubuntu_1804_desktop has result after scatter [6, 12, 18]\n",
            "Process 7 of 8 on ubuntu_1804_desktop has result after scatter [8, 16, 24]\n"
          ]
        }
      ],
      "source": [
        "! mpirun --allow-run-as-root -np 8 python3 14scatter.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvCNDN56s71A"
      },
      "source": [
        "Zadanie. Proszę napisać program który generuje tablicę tablic liczb w procesie głównym i rozsyłą je do pozostałych procesów. Procesy odbierają swoją część tablicy i wyliczają oraz wypisują jej sumę. Proszę napisac program z wykorzystaniem komunikacji kolektywnej"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting zadanie2.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile zadanie2.py\n",
        "from mpi4py import MPI\n",
        "\n",
        "# Create a list of lists to be scattered.\n",
        "def genListOfLists(numElements):\n",
        "    data = [[0]*3 for i in range(numElements)]\n",
        "    for i in range(numElements):\n",
        "        #make small lists of 3 distinct elements\n",
        "        smallerList = []\n",
        "        for j in range(1,4):\n",
        "            smallerList = smallerList + [(i+1)*j]\n",
        "        # place the small list in the larger list\n",
        "        data[i] = smallerList\n",
        "    return data\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()            #number of the process running the code\n",
        "    numProcesses = comm.Get_size()  #total number of processes running\n",
        "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
        "\n",
        "    # in mpi4py, the lowercase scatter method only works on lists whose size\n",
        "    # is the total number of processes.\n",
        "    numElements = numProcesses      #total elements in list created by master process\n",
        "\n",
        "    # however, the list can contain lists, like this list of 3-element lists,\n",
        "    # for example this list of four 3-element lists:\n",
        "    #     [[1, 2, 3], [2, 4, 6], [3, 6, 9], [4, 8, 12]]\n",
        "\n",
        "    if id == 0:\n",
        "        data = genListOfLists(numElements)\n",
        "        print(\"Master {} of {} on {} has created list: {}\"\\\n",
        "        .format(id, numProcesses, myHostName, data))\n",
        "    else:\n",
        "        data = None\n",
        "        print(\"Worker Process {} of {} on {} starts with {}\"\\\n",
        "        .format(id, numProcesses, myHostName, data))\n",
        "\n",
        "    #scatter one small list in the large list on node 0 to each of the processes\n",
        "    list_result = comm.scatter(data, root=0)\n",
        "\n",
        "    #print(\"Process {} of {} on {} has result after scatter {}\"\\\n",
        "    #.format(id, numProcesses, myHostName, result))\n",
        "    result = 0\n",
        "    for element in list_result:\n",
        "        result+= element\n",
        "\n",
        "    print(\"Proces {} z {} na {} wyliczył sumę tablicy {}\"\\\n",
        "    .format(id, numProcesses, myHostName, result))\n",
        "\n",
        "    if id == 0:\n",
        "        print(\"Master {} of {} on {} has original list after scatter: {}\"\\\n",
        "        .format(id, numProcesses, myHostName, data))\n",
        "\n",
        "########## Run the main function\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Worker Process 7 of 8 on ubuntu_1804_desktop starts with None\n",
            "Worker Process 3 of 8 on ubuntu_1804_desktop starts with None\n",
            "Worker Process 4 of 8 on ubuntu_1804_desktop starts with None\n",
            "Worker Process 5 of 8 on ubuntu_1804_desktop starts with None\n",
            "Worker Process 1 of 8 on ubuntu_1804_desktop starts with None\n",
            "Master 0 of 8 on ubuntu_1804_desktop has created list: [[1, 2, 3], [2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15], [6, 12, 18], [7, 14, 21], [8, 16, 24]]\n",
            "Worker Process 6 of 8 on ubuntu_1804_desktop starts with None\n",
            "Worker Process 2 of 8 on ubuntu_1804_desktop starts with None\n",
            "Proces 5 z 8 na ubuntu_1804_desktop wyliczył sumę tablicy 36\n",
            "Proces 0 z 8 na ubuntu_1804_desktop wyliczył sumę tablicy 6\n",
            "Proces 3 z 8 na ubuntu_1804_desktop wyliczył sumę tablicy 24\n",
            "Proces 4 z 8 na ubuntu_1804_desktop wyliczył sumę tablicy 30\n",
            "Proces 2 z 8 na ubuntu_1804_desktop wyliczył sumę tablicy 18\n",
            "Proces 6 z 8 na ubuntu_1804_desktop wyliczył sumę tablicy 42\n",
            "Proces 1 z 8 na ubuntu_1804_desktop wyliczył sumę tablicy 12\n",
            "Proces 7 z 8 na ubuntu_1804_desktop wyliczył sumę tablicy 48\n",
            "Master 0 of 8 on ubuntu_1804_desktop has original list after scatter: [[1, 2, 3], [2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15], [6, 12, 18], [7, 14, 21], [8, 16, 24]]\n"
          ]
        }
      ],
      "source": [
        "! mpirun --allow-run-as-root -np 8 python3 zadanie2.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "PRIR_mpi4py.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
